{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGWj1TUExHUg"
      },
      "source": [
        "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L33GP4kxHUi"
      },
      "source": [
        "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
        "\n",
        "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVXXD7sPxHUi"
      },
      "source": [
        "## Datos predicción precio de automóviles\n",
        "\n",
        "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir si el precio del automóvil es alto o no. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXbInqG9xHUj"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DLYi5pmxHUl"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "\n",
        "# Lectura de la información de archivo .csv\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
        "\n",
        "# Preprocesamiento de datos para el taller\n",
        "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
        "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
        "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
        "data = data.drop(['Model', 'Price'], axis=1)\n",
        "\n",
        "# Visualización dataset\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSH9KjoMxHUl"
      },
      "outputs": [],
      "source": [
        "# Separación de variables predictoras (X) y variable de interés (y)\n",
        "y = data['HighPrice']\n",
        "X = data.drop(['HighPrice'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByUElD7FxHUm"
      },
      "outputs": [],
      "source": [
        "# Separación de datos en set de entrenamiento y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMjwKI54xHUm"
      },
      "source": [
        "### Punto 1 - Árbol de decisión manual\n",
        "\n",
        "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el acurracy del modelo en el set de test."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ArbolRegresionManual():\n",
        "  def __init__(\n",
        "      self,\n",
        "      X: pd.DataFrame,\n",
        "      y: pd.Series,\n",
        "      n_samples=1,\n",
        "      level = 0\n",
        "  ):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.n_samples = n_samples\n",
        "    self.level = level\n",
        "    self.features = X.columns\n",
        "\n",
        "  @staticmethod\n",
        "  def MSE_particion(y_l, y_r):\n",
        "    mse = (sum([(x-y_l.mean())**2 for x in y_l])+sum([(x-y_r.mean())**2 for x in y_r]))/(len(y_l)+len(y_r))\n",
        "    return mse\n",
        "    \n",
        "  @staticmethod\n",
        "  def mejor_particion(self): \n",
        "    mejor_particion = [0,0,np.inf]  # j, split, mse\n",
        "    for j in features:\n",
        "      splits = X.loc[:,j].unique()\n",
        "      for split in splits:\n",
        "        mse = MSE_particion(y[X[j] < split], y[X[j] >= split])\n",
        "        mejor_particion = [j, split, mse] if mse < mejor_particion[2]\n",
        "          \n",
        "    mejor_particion[1] = -1 if (len(np.unique(X.loc[X[mejor_particion[0]] < mejor_particion[1],mejor_particion[0]])) == 0) or (len(np.unique(X.loc[X[mejor_particion[0]] >= mejor_particion[1],mejor_particion[0]])) == 0)\n",
        "\n",
        "    return mejor_particion\n",
        "  \n",
        "  \n",
        "  @staticmethod\n",
        "  def tree_grow(self):\n",
        "    if X.shape[0] == 1:\n",
        "      tree = dict(y_pred=y.iloc[:1].values[0], level=level, split=-1, n_samples=1, MSE=0)\n",
        "      return(tree)\n",
        "    \n",
        "    j, split, mse = mejor_particion(X, y)\n",
        "    tree = dict(y_pred=y.mean(), level=level, split=-1, n_samples=X.shape[0], MSE=mse)\n",
        "    \n",
        "    return tree if mse == np.inf\n",
        "    return tree if (len(np.unique(X[X[j] < split][j])) <= 1) or (len(np.unique(X[X[j] >= split][j])) <= 1)\n",
        "    \n",
        "    # Continuar creando la partición\n",
        "    X_l, y_l = X[X[j] < split], y[X[j] < split]\n",
        "    X_r, y_r = X[X[j] >= split], y[X[j] >= split]\n",
        "    tree['split'] = [j, split]\n",
        "    # Siguiente iteración para cada partición\n",
        "    tree['sl'] = tree_grow(X_l, y_l, level + 1)\n",
        "    tree['sr'] = tree_grow(X_r, y_r, level + 1)\n",
        "    return tree\n",
        "\n",
        "  def tree_predict(X, tree):\n",
        "      \n",
        "    predicted = np.ones(X.shape[0])\n",
        "    \n",
        "    # Revisar si es el nodo final\n",
        "    if tree['split'] == -1:\n",
        "      predicted = predicted * tree['y_pred']   \n",
        "    else:\n",
        "      j, split = tree['split']\n",
        "      filter_l = (X.loc[:, j] < split)\n",
        "      X_l = X.loc[filter_l]\n",
        "      X_r = X.loc[~filter_l]\n",
        "      predicted[filter_l] = tree_predict(X_l, tree['sl'])\n",
        "      predicted[~filter_l] = tree_predict(X_r, tree['sr'])\n",
        "    return predicted\n",
        "\n"
      ],
      "metadata": {
        "id": "iAk4TtWW1Xeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTQvzrjrxHUn"
      },
      "outputs": [],
      "source": [
        "# Celda 1\n",
        "tree = tree_grow(bikes[[\"hour\", \"workingday\"]], bikes.total, level=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpHqcY2zxHUn"
      },
      "source": [
        "### Punto 2 - Bagging manual\n",
        "\n",
        "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de clasificación y comenten sobre el desempeño del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvJIMaNRxHUn"
      },
      "outputs": [],
      "source": [
        "# Celda 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uX4kNS4xHUo"
      },
      "source": [
        "### Punto 3 - Bagging con librería\n",
        "\n",
        "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de clasificación y el parámetro `max_features` igual a `log(n_features)`. Presenten el acurracy del modelo en el set de test y comenten sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUn5z02XxHUo"
      },
      "outputs": [],
      "source": [
        "# Celda 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hjPVDSuxHUo"
      },
      "source": [
        "### Punto 4 - Random forest con librería\n",
        "\n",
        "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para clasificación y presenten el acurracy del modelo en el set de test y comenten sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ0NG8tUxHUp"
      },
      "outputs": [],
      "source": [
        "# Celda 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFkZX3p4xHUp"
      },
      "source": [
        "### Punto 5 - Calibración de parámetros Random forest\n",
        "\n",
        "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para clasificación. Presenten el acurracy del modelo en el set de test, comenten sus resultados y análicen cómo cada parámetro afecta el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZuu6646xHUp"
      },
      "outputs": [],
      "source": [
        "# Celda 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjiY8AQGxHUq"
      },
      "source": [
        "### Punto 6 - XGBoost con librería\n",
        "\n",
        "En la celda 6 implementen un modelo XGBoost de clasificación con la librería sklearn, presenten el acurracy del modelo en el set de test y comenten sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IepbLnppxHUq"
      },
      "outputs": [],
      "source": [
        "# Celda 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oR5nH2fxHUq"
      },
      "source": [
        "### Punto 7 - Calibración de parámetros XGBoost\n",
        "\n",
        "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para clasificación. Presenten el acurracy del modelo en el set de test, comenten sus resultados y análicen cómo cada parámetro afecta el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbr2Nv0OxHUr"
      },
      "outputs": [],
      "source": [
        "# Celda 7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ofpOuqlxHUr"
      },
      "source": [
        "### Punto 8 - Comparación y análisis de resultados\n",
        "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gckq_jfNxHUr"
      },
      "outputs": [],
      "source": [
        "# Celda 8\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "S2TC1_RandomForests_Boosting.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}